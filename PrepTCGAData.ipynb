{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/mathiane/LNENWork/SamplesWSITCGA\"\n",
    "class_svs = \"LUAD\"\n",
    "patient_id  = os.listdir(os.path.join(root, class_svs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TCGA-05-4244-01Z-00-DX1.jpg',\n",
       " 'TCGA-05-4382-01Z-00-DX1.svs',\n",
       " 'TCGA-05-4395-01Z-00-DX1.svs',\n",
       " 'TCGA-05-4382-01Z-00-DX1.jpg',\n",
       " 'TCGA-05-4397-01Z-00-DX1.jpg',\n",
       " 'TCGA-05-4395-01Z-00-DX1.jpg',\n",
       " 'TCGA-05-4250-01Z-00-DX1.svs',\n",
       " 'TCGA-05-4249-01Z-00-DX1.jpg',\n",
       " 'TCGA-05-4250-01Z-00-DX1.jpg',\n",
       " 'TCGA-05-4244-01Z-00-DX1.svs',\n",
       " 'TCGA-05-4245-01Z-00-DX1.svs',\n",
       " 'TCGA-05-4396-01Z-00-DX1.svs',\n",
       " 'TCGA-05-4245-01Z-00-DX1.jpg',\n",
       " 'TCGA-05-4397-01Z-00-DX1.svs',\n",
       " 'TCGA-05-4249-01Z-00-DX1.svs',\n",
       " 'TCGA-05-4396-01Z-00-DX1.jpg']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = [p.split(\".\")[0] for p in patient_id  if p.split(\".\")[1] == \"svs\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"case_id\":patient_id,\n",
    "             \"slide_id\" : patient_id,\n",
    "             \"label_id\" : np.repeat(class_svs, [len(patient_id)], axis=0).tolist()}).to_csv(\"data/LUAD/slides_format.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_svs = \"LUSC\"\n",
    "patient_id  = os.listdir(os.path.join(root, class_svs))\n",
    "patient_id = [p.split(\".\")[0] for p in patient_id  if p.split(\".\")[1] == \"svs\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"case_id\": patient_id,\n",
    "             \"slide_id\" : patient_id,\n",
    "             \"label_id\" : np.repeat(class_svs, [len(patient_id)], axis=0).tolist()}).to_csv(\"data/LUSC/slides_format.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRY READ PANSAS\" PARQUET FILE\n",
    "root_eval = \"/home/mathiane/LNENWork/DDS_roformer/DDS-RoFormerMIL/data/results/task_2_tumor_subtyping/debug/label_frac=100/RoPEAMIL_pixel/eval/2024-02-14_11-16-42\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-662445536147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"patients_preds.parquet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fold=0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"split=test\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"0f3b2fa954d54f9982d3a4a3e87ae3b9-0.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/HaloAE/lib/python3.6/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \"\"\"\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/HaloAE/lib/python3.6/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mget_engine\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         raise ImportError(\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;34m\"Unable to find a usable engine; \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;34m\"tried using: 'pyarrow', 'fastparquet'.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;34m\"A suitable version of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "pd.read_parquet(os.path.join(root_eval, \"patients_preds.parquet\", \"fold=0\", \"split=test\",  \"0f3b2fa954d54f9982d3a4a3e87ae3b9-0.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HaloAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
